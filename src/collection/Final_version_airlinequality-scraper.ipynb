{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "022d075e",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Scraping data from airlinequality.com</span>\n",
    "To understand how airline reviews have changed due to the COVID-19 pandemic, we will set up a scraper using the BeautifulSoup library from python. In this jupyter notebook we will discuss three chapters:\n",
    "\n",
    "1. The prerequisets for scraping\n",
    "2. The airlinequality.com scraper\n",
    "3. Saving the scraped data in a csv file\n",
    "\n",
    "Throughout this notebook the code will be explained and their purpose will be stated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0893a05",
   "metadata": {},
   "source": [
    "# 1. The prerequisets for scraping\n",
    "Before the airlinequality website can be scraped a few things need to be done. Firstly, important libraries need to be imported for the code to run. Secondly, we have to generate the seeds for all different airline reviews. Lastly, we will need to be able to generate all page url's so that we can navigate all different review pages.   \n",
    "\n",
    "## 1.1 Importing necessary libraries\n",
    "In the first cell of our notebook we import the libraries that are necessary to run our code. These libraries are needed for the following:\n",
    "\n",
    "* The requests library will allow us to load the web data of the airlinequality website and save it in HTML.\n",
    "* The BeautifulSoup library will allow us to extract data from HTML files.\n",
    "* As we want to extract quite some data, we will need the sleep package to obey retrieval limits.\n",
    "* The math library is necessary for a function to count the total pages of a review for a specific airline. More about that later.\n",
    "* The csv library will be used to store the scraped data in a csv file.\n",
    "* The datetime library is necessary to know exactly when the data was scraped from the website as reviews will be added frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674031aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import math\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4e455",
   "metadata": {},
   "source": [
    "## 1.2 Seed generation\n",
    "It is important for research to examine reviews of multiple airlines thus we need to have a simple method that can generate different airline review page url's. We do this by making a function that will generate these seeds. We describe the three necessary steps to achieve this in this paragraph.  \n",
    "\n",
    "Firstly, we define the 'base url' which is the part of the url that is the same for all different airline reviews. The home page is https://www.airlinequality.com. When you want to see all airline reviews you can got to Airline Reviews -> A-Z Airline Reviews which gives us an overview of all airlines which have reviews on the website (see image below).\n",
    "<img src=\"../../docs/A-Z_reviews.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e96d914",
   "metadata": {},
   "source": [
    "If you click on AB Aviation and Adria Airways they would have the following url:\n",
    "- https://www.airlinequality.com/airline-reviews/ab-aviation\n",
    "- https://www.airlinequality.com/airline-reviews/adria-airways\n",
    "\n",
    "Thus, we can conclude that there is a constant part in this url which we will define as our base url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4502dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the base url.\n",
    "base_url = 'https://www.airlinequality.com/airline-reviews/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda6330",
   "metadata": {},
   "source": [
    "Secondly, a list of airlines of interest is defined. It is important that these are written exactly the same way as they are presented in the url of the airlinequality website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e698398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of airlines. This can obviously be changed depending on the interest of the researcher.\n",
    "airlines = ['klm-royal-dutch-airlines', 'air-china', 'american-airlines', 'air-caraibes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed665cc1",
   "metadata": {},
   "source": [
    "Lastly, a function is defined where the input is the base url and the airline list. The function has a for loop that connects the base url with each airline name from the airline list and stores the result in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7220e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_airline_urls(base_url, airline):\n",
    "    \"\"\"\n",
    "    A function to generate a list of urls for airlines on airlinequality.\n",
    "  \n",
    "    Two parameters:\n",
    "        base_url: The part of the url that stays the same for each airline review on airline quality.\n",
    "        airline: A list of airlines that need to be scraped. They need to be written as they are presented in the url\n",
    "        of airlinequality\n",
    "    \n",
    "    Returns:\n",
    "        A list of airline review url's\n",
    "    \"\"\"\n",
    "    page_urls = []\n",
    "    for airline in airlines:\n",
    "        full_url = base_url + airline\n",
    "        page_urls.append(full_url)\n",
    "    return page_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d5545",
   "metadata": {},
   "source": [
    "Here we assign the results of the function to a list called airline_urls and show the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd812cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.airlinequality.com/airline-reviews/klm-royal-dutch-airlines', 'https://www.airlinequality.com/airline-reviews/air-china', 'https://www.airlinequality.com/airline-reviews/american-airlines', 'https://www.airlinequality.com/airline-reviews/air-caraibes']\n"
     ]
    }
   ],
   "source": [
    "# A list that stores all airline review urls.  \n",
    "airline_urls = generate_airline_urls(base_url, airlines)\n",
    "print(airline_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20747657",
   "metadata": {},
   "source": [
    "When the URL of a new airline needs to be generated, the new airline can be added to the back of the 'airlines' list. Thereafter, 'airline_urls[-1]' can be printed to quickly generate a new airline review url. We assigned airline_urls[-1] to a variable which allows us to quickly scrape the page of a different airline when testing the scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "679d0f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.airlinequality.com/airline-reviews/air-caraibes\n"
     ]
    }
   ],
   "source": [
    "# A variable that gives the airline url of the airline at the end of the 'airlines' list \n",
    "Newest_page_url = airline_urls[-1]\n",
    "print(Newest_page_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7e8fd",
   "metadata": {},
   "source": [
    "## 1.3 Navigating all the different review pages for an airline\n",
    "To navigate the different page urls for a specific airline we have set up a function called \"generate_page_urls\". Information about the function is given in the docstring. We use a for loop and a counter to generate all page URL's. It is important that the range of the counter is 'num_pages'+ 1 as python considers the first element in a list to be 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83319143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate all page urls\n",
    "def generate_page_urls(airline_url, num_pages):\n",
    "    \"\"\"\n",
    "    A function to generate all page urls for airlines on airlinequality.\n",
    "  \n",
    "    Two parameters:\n",
    "        airline_url: The airline URL of which you want to generate page url's \n",
    "        num_pages: the amount of pages of which you want to generate page url's\n",
    "        \n",
    "    Returns:\n",
    "        A list of airline page url's\n",
    "    \"\"\"\n",
    "    \n",
    "    page_urls = []    \n",
    "    for counter in range(1, num_pages + 1):\n",
    "        full_url = airline_url + \"/page/\" + str(counter)\n",
    "        page_urls.append(full_url)\n",
    "        \n",
    "    return page_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ff0f4",
   "metadata": {},
   "source": [
    "Here we use the \"airline_urls\" list of the previous paragraph to generate the first two pages of the KLM reviews on airlinequality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0727f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.airlinequality.com/airline-reviews/klm-royal-dutch-airlines/page/1', 'https://www.airlinequality.com/airline-reviews/klm-royal-dutch-airlines/page/2']\n"
     ]
    }
   ],
   "source": [
    "# Page_url function for KLM\n",
    "print(generate_page_urls(airline_urls[0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9b3cb",
   "metadata": {},
   "source": [
    "### <ins>Total page function</ins>\n",
    "However, to scrape all the pages of the airline we will need the total amount of pages. To avoid looking this up manually for each new airline, we have set up a function that calculates this. On the first page of the airline review URL (the 'airline_urls' list) the total reviews are given in text. We use this text (highlighted in red in the image below) to generate the total pages.\n",
    "<img src=\"../../docs/total_pages.png\" />\n",
    "We modify this text in three ways to get the total pages:\n",
    "1. We remove the unnecesary text with the replace function so that the total reviews remain.\n",
    "2. We transform the total reviews to a float so that we can use functions from the math package.\n",
    "3. We calculate the total pages by dividing the total reviews by 10 and rounding it upwards with the math.ceil function. We round it by 10 because the default way airlinequality shows reviews is in groups of 10 per page. Futhermore, it needs to be rounded upwards as leftover reviews are stored on the last page.\n",
    "\n",
    "Once we have the total pages it could be used in the 'generate_page_urls' function to generate all page_urls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a8055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the total pages for an airline\n",
    "def total_pages(airline_url):\n",
    "    \"\"\"\n",
    "    A function to generate the total pages.\n",
    "  \n",
    "    One parameters:\n",
    "        airline_url: The airline URL of which you want to generate the total pages\n",
    "        \n",
    "    Returns:\n",
    "        The total pages of an airline on airlinequality.com\n",
    "    \"\"\"\n",
    "    res = requests.get(airline_url)\n",
    "    review_source_code = res.text\n",
    "    soup = BeautifulSoup(review_source_code, 'html.parser')\n",
    "    \n",
    "    text = soup.find(class_='pagination-total').get_text()\n",
    "    clean = text.replace('1 to 10 of ','') # removing unnecessary text\n",
    "    total_reviews = float(clean.replace(' Reviews','')) # removing unnecessary text and transforming variable to a float\n",
    "    total_pages = math.ceil(total_reviews/10) # dividing the number by ten and rounding it upwards\n",
    "\n",
    "    return print(total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ce2bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "# The total pages for KLM (123 at 14-10-21)\n",
    "total_pages(airline_urls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b5d1a",
   "metadata": {},
   "source": [
    "# 2. The airlinequality.com scraper\n",
    "In this chapter we will introduce our scraper function. The function will have as input the list of page urls which we were able to gather in the previous chapter. With the use of a for loop we are able to iterate over all the reviews on the different page url's. Each review has a similair structure as shown in the image below. In the top half of the review the title, name of the writer, the country of the reviewer, review verify status, and the date the review was posted. In the bottom half of the review a table is displayed showing various information. Firstly, we will discuss how we gather data from the top half of the review. Secondly, we will discuss how we have gathered the data in the bottom half of the review which is a bit more complex. Thirdly, it will be explained why the sleep() function and datetime.now() are used to finalize the scraper function.\n",
    "<img src=\"../../docs/review_example.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca08eda",
   "metadata": {},
   "source": [
    "## 2.1 scraping the top half of the review\n",
    "This half of the review is quite straight forward to scrape. We look for the tags in which the text is located and use the find() function of BeautifulSoup together with get_text(). For the date the review was published we instead look for the attribute \"datetime\" within the \"time\" tag. That is because this data is a bit more easier to convert to a date variable in R if we want to conduct an analysis (see image below).\n",
    "<img src=\"../../docs/date_review_is_published.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a5c4f8",
   "metadata": {},
   "source": [
    "The verify status, the review rating and the country of the reviewer needed a different approach as in older reviews this data can sometimes be missing (see image below highlighted in red).\n",
    "<img src=\"../../docs/tophalf_old.png\" />\n",
    "Therefore, we have given the verify status and the review rating a default value and set up an if-condition. The find() function will return None if nothing was found found thus we use != None for our if-condition. If the data is not there the default values are returned. If the data is there we use the same approach as discussed before to assign the text to a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3777059",
   "metadata": {},
   "source": [
    "For the Verify status there were some complications due to differences between older and newer reviews (see images below).\n",
    "<img src=\"../../docs/verify_status.png\" />\n",
    "\n",
    "Although .find('strong').get_text() might work in 2021 and 2017 it will generate wrong text in 2015. Therefore we have corrected this with an if-condition: \n",
    "- if review_verify == \"Delta Air Lines\": \n",
    "    review_verify = 'n/a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd91d80",
   "metadata": {},
   "source": [
    "For the country of the reviewer we also had to be creative as this data was akwardly positioned inbetween two different tags (see image below).\n",
    "<img src=\"../../docs/country.png\" />\n",
    "Thus, to extract this data we use the previousSibling() function which return the previous element of a specific element. As the country is given before the time we used the 'time' tag. As the country is always inbetween brackets we used these brackets for an if-else condition basically if brackets are found remove them with replace() so that only the country is returned. If the brackets are not found the country is given a default value, similair to the verify status and review rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d1e472",
   "metadata": {},
   "source": [
    "## 2.2 scraping the bottom half of the review\n",
    "To scrape the table of the review we first save the source code of all table rows in a list using find_all(). Afterwards we iterate over the list of rows. Similairly, as some data in the top half of the review the table can be completely empty (see image below), thus default values are given. \n",
    "<img src=\"../../docs/bottomhalf_old.png\" />\n",
    "We once again use if-conditions to change the default values if the specific class is found in the row. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431789b3",
   "metadata": {},
   "source": [
    "For the star rating we needed to adopt a different strategy because if we would use row.find(class_= \"stars\").get_text() we would get '12345' for all ratings (see image below). \n",
    "<img src=\"../../docs/star_ratings.png\" />\n",
    "Thus, instead we focus on the column with the star rating and with col.find_all(class_ = \"star fill\") we are able to store the ratings in a list. With the len() function we are then able to accurately get the star rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b232856",
   "metadata": {},
   "source": [
    "In older reviews it was sometimes possible to state 'N/A' for a specific star rating (see image below).\n",
    "<img src=\"../../docs/table_na.png\" />\n",
    "With the code explained above the star rating 0 would be assigned to all ratings in this review as the function find_all() returns an empty list if nothing was found. Thus, we have corrected that with an if-condition that states:                     if seat_comfort == 0:\n",
    "    seat_comfort = 'n/a' \n",
    "This is safe as it is impossible to give a 0 star rating. This was done for all values with a star rating.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126e7c1",
   "metadata": {},
   "source": [
    "## 2.3 Finishing the scraper\n",
    "To finish the scraper we use sleep() function to avoid breaching the retrieval limit. In addition, when the scrape function gets executed we added a print of the current time with the datetime.now() function. The current time can than be used in the csv file (in the title) so that it is clear at what exact the moment the data has been scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "365d1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scraper\n",
    "def scrape(page_urls):\n",
    "    \"\"\"\n",
    "    A function that scrapes the data of the airlinequality.com website\n",
    "  \n",
    "    One parameter:\n",
    "        page_urls: A list of page urls of an airline review on airlinequality.com\n",
    "        \n",
    "    Returns:\n",
    "        A list of dictionaries with all the available airline review data of a specific airline, with the current date and time \n",
    "    \"\"\"\n",
    "    \n",
    "    review_data = [] \n",
    "    for page_url in page_urls: \n",
    "        res = requests.get(page_url)\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "        reviews = soup.find_all(class_= 'media')\n",
    "        \n",
    "        # older reviews sometimes do not have a rating given which mean a defaut value is added\n",
    "        review_rating = 'n/a'\n",
    "        \n",
    "        #  simiair to review rating the verify status is sometimes not given thus verify gets a default 'Not Verified' value  \n",
    "        review_verify = 'Not Verified' \n",
    "        \n",
    "        for review in reviews:\n",
    "            review_writer = review.find(\"span\", itemprop=\"name\").get_text() # the name of the review writer \n",
    "            review_title = review.find(\"h2\").get_text() # review title\n",
    "            review_published = review.find(\"time\").attrs[\"datetime\"] # date the review is published\n",
    "            \n",
    "            # in older reviews the country is sometimes leftout which is why we assign the value 'n/a' to it initially\n",
    "            # the country is always inbetween brackets that is why we look if they are present in the string\n",
    "            h3 = review.find('h3')\n",
    "            review_country = h3.find('time').previousSibling\n",
    "            if \"(\" not in review_country or \")\" not in review_country: \n",
    "                review_country = 'n/a'\n",
    "            else:\n",
    "                review_country = review_country.replace(' (','').replace(') ','')\n",
    "            \n",
    "            # the find function returns None if nothing is found \n",
    "            # thus the following if-conditions will adjust the default values if the rating and verify statements are given  \n",
    "            if review.find(\"span\" , itemprop=\"ratingValue\") != None:  \n",
    "                review_rating = review.find(\"span\" , itemprop=\"ratingValue\").get_text() # review rating\n",
    "            \n",
    "            # if the verify status is mentioned than it will be in the strong tag\n",
    "            if review.find('strong') != None:  \n",
    "                review_verify = review.find(\"strong\").get_text() # verified or not\n",
    "                \n",
    "                # correction for the delta air lines text (see 2.1)\n",
    "                if review_verify == \"Delta Air Lines\":\n",
    "                    review_verify = 'n/a'\n",
    "            \n",
    "        # table information\n",
    "            # default value if the star rating is not present in the review\n",
    "            Type_Of_Traveller = 'n/a'\n",
    "            cabin_flown  = 'n/a'\n",
    "            route  = 'n/a'\n",
    "            aircraft = 'n/a'\n",
    "            date_flown = 'n/a'\n",
    "            value_for_money = 'n/a'\n",
    "            ground_service = 'n/a'\n",
    "            seat_comfort = 'n/a'\n",
    "            cabin_staff_service = 'n/a'\n",
    "            food_and_beverages = 'n/a'\n",
    "            inflight_entertainment = 'n/a'\n",
    "            wifi_and_connectivity = 'n/a'\n",
    "            recommended = 'n/a'\n",
    "            \n",
    "            # html code for the table and all table rows in a list\n",
    "            table = review.find('table', attrs={'class':'review-ratings'})\n",
    "            all_rows = table.find_all('tr')\n",
    "            \n",
    "            # for every table in the review data is being saved and assigned to a value\n",
    "            for row in all_rows:\n",
    "                if row.find(class_= \"type_of_traveller\") != None:\n",
    "                    Type_Of_Traveller =  row.find(class_= \"review-value\").get_text()\n",
    "                if row.find(class_= \"cabin_flown\") != None: \n",
    "                    cabin_flown = row.find(class_= \"review-value\").get_text() \n",
    "                if row.find(class_= \"route\") != None: \n",
    "                    route = row.find(class_= \"review-value\").get_text() \n",
    "                if row.find(class_= \"aircraft\") != None: \n",
    "                    aircraft = row.find(class_= \"review-value\").get_text()\n",
    "                if row.find(class_= \"date_flown\") != None:\n",
    "                    date_flown = row.find(class_= \"review-value\").get_text()\n",
    "                if row.find(class_= \"recommended\") != None:\n",
    "                    recommended = row.find(class_= \"review-value\").get_text()\n",
    "                    \n",
    "                # extracting the star ratings by calculating the lenght of the list create by find_all (class_ = \"star fill\")\n",
    "                if row.find(class_= \"value_for_money\") != None:\n",
    "                    col = row.find(class_= \"stars\")\n",
    "                    value_for_money = len(col.find_all(class_ = \"star fill\"))\n",
    "                    \n",
    "                # some older reviews do not work with star ratings but can give N/A as a value. This means that the value \n",
    "                # above will be 0, however this score was not actually given by the reviewer. this if condition corrects this\n",
    "                    if value_for_money == 0:\n",
    "                        value_for_money = 'n/a'\n",
    "                        \n",
    "                if row.find(class_= \"ground_service\") != None:\n",
    "                    col = row.find(class_= \"stars\")\n",
    "                    ground_service = len(col.find_all(class_ = \"star fill\"))\n",
    "                    if ground_service == 0:\n",
    "                        ground_service = 'n/a'     \n",
    "                    \n",
    "                if row.find(class_= \"seat_comfort\") != None:\n",
    "                    col = row.find(class_= \"stars\")\n",
    "                    seat_comfort = len(col.find_all(class_ = \"star fill\"))\n",
    "                    if seat_comfort == 0:\n",
    "                        seat_comfort = 'n/a'\n",
    "                        \n",
    "                if row.find(class_= \"cabin_staff_service\") != None:\n",
    "                    col = row.find(class_= \"stars\")\n",
    "                    cabin_staff_service = len(col.find_all(class_ = \"star fill\"))\n",
    "                    if cabin_staff_service == 0:\n",
    "                        cabin_staff_service = 'n/a'\n",
    "                        \n",
    "                if row.find(class_= \"food_and_beverages\") != None:\n",
    "                    col = row.find(class_= \"stars\")\n",
    "                    food_and_beverages = len(col.find_all(class_ = \"star fill\"))\n",
    "                    if food_and_beverages == 0:\n",
    "                        food_and_beverages = 'n/a'\n",
    "                    \n",
    "                if row.find(class_= \"inflight_entertainment\") != None:\n",
    "                    col = row.find(class_= \"stars\")\n",
    "                    inflight_entertainment = len(col.find_all(class_ = \"star fill\"))\n",
    "                    if inflight_entertainment == 0:\n",
    "                        inflight_entertainment = 'n/a'\n",
    "                    \n",
    "                if row.find(class_= \"wifi_and_connectivity\") != None:\n",
    "                    col = row.find(class_= \"stars\")\n",
    "                    wifi_and_connectivity = len(col.find_all(class_ = \"star fill\"))\n",
    "                    if wifi_and_connectivity == 0:\n",
    "                        wifi_and_connectivity = 'n/a'\n",
    "\n",
    "            # Saving the data in a dictionary\n",
    "            review_data.append({'Review Rating': review_rating,\n",
    "                                'Review Writer': review_writer,\n",
    "                                'Title': review_title,\n",
    "                                'Date Published': review_published, \n",
    "                                'Verify Status':  review_verify,\n",
    "                                'Country': review_country,\n",
    "                                'Aircraft': aircraft,\n",
    "                                'Route': route,\n",
    "                                'Type Of Traveller': Type_Of_Traveller,\n",
    "                                'Seat type': cabin_flown,\n",
    "                                'Date Flown': date_flown,\n",
    "                                'Value For Money (rating out of five)': value_for_money,\n",
    "                                'Seat Comfort (rating out of five)': seat_comfort,\n",
    "                                'Cabin Staff Service (rating out of five)': cabin_staff_service,\n",
    "                                'Food & Beverages (rating out of five)': food_and_beverages,\n",
    "                                'inflight_entertainment (rating out of five)': inflight_entertainment,\n",
    "                                'Wifi & Connectivity (rating out of five)': wifi_and_connectivity,\n",
    "                                'Ground Service (rating out of five)': ground_service,\n",
    "                                'Recommended': recommended})   \n",
    "    sleep(5)\n",
    "    print(datetime.now())\n",
    "    return review_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f81829d",
   "metadata": {},
   "source": [
    "The scraped data will be saved as \"KLM_data\". We have includes 123 pages which is the total pages that we found using the total_pages() function we used earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a36d1341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-17 15:36:20.974732\n",
      "[{'Review Rating': '1', 'Review Writer': 'Martin Dite', 'Title': '\"time moved back without informing us\"', 'Date Published': '2021-10-16', 'Verify Status': 'Trip Verified', 'Country': 'Czech Republic', 'Aircraft': 'n/a', 'Route': 'Amsterdam to Prague', 'Type Of Traveller': 'Solo Leisure', 'Seat type': 'Economy Class', 'Date Flown': 'October 2021', 'Value For Money (rating out of five)': 1, 'Seat Comfort (rating out of five)': 'n/a', 'Cabin Staff Service (rating out of five)': 'n/a', 'Food & Beverages (rating out of five)': 'n/a', 'inflight_entertainment (rating out of five)': 'n/a', 'Wifi & Connectivity (rating out of five)': 'n/a', 'Ground Service (rating out of five)': 1, 'Recommended': 'no'}, {'Review Rating': '8', 'Review Writer': 'Anders Pedersen', 'Title': '\"good value for money\"', 'Date Published': '2021-10-15', 'Verify Status': 'Not Verified', 'Country': 'Vietnam', 'Aircraft': 'Boeing 787-8 and A330', 'Route': 'Copenhagen to Kigali via Amsterdam', 'Type Of Traveller': 'Business', 'Seat type': 'Economy Class', 'Date Flown': 'October 2021', 'Value For Money (rating out of five)': 5, 'Seat Comfort (rating out of five)': 4, 'Cabin Staff Service (rating out of five)': 4, 'Food & Beverages (rating out of five)': 3, 'inflight_entertainment (rating out of five)': 2, 'Wifi & Connectivity (rating out of five)': 1, 'Ground Service (rating out of five)': 5, 'Recommended': 'yes'}, {'Review Rating': '2', 'Review Writer': 'Vitaliy Kryvosheiev', 'Title': '\"rude and ignorant cabin staff\"', 'Date Published': '2021-10-08', 'Verify Status': 'Not Verified', 'Country': 'United States', 'Aircraft': 'n/a', 'Route': 'Amsterdam to New York', 'Type Of Traveller': 'Solo Leisure', 'Seat type': 'Business Class', 'Date Flown': 'September 2021', 'Value For Money (rating out of five)': 2, 'Seat Comfort (rating out of five)': 4, 'Cabin Staff Service (rating out of five)': 1, 'Food & Beverages (rating out of five)': 2, 'inflight_entertainment (rating out of five)': 2, 'Wifi & Connectivity (rating out of five)': 'n/a', 'Ground Service (rating out of five)': 3, 'Recommended': 'no'}, {'Review Rating': '4', 'Review Writer': 'Venkata Adapa', 'Title': '\"8000 rupees for additional baggage\"', 'Date Published': '2021-10-05', 'Verify Status': 'Not Verified', 'Country': 'Canada', 'Aircraft': 'n/a', 'Route': 'Delhi to Mexico via Amsterdam', 'Type Of Traveller': 'Solo Leisure', 'Seat type': 'Economy Class', 'Date Flown': 'September 2021', 'Value For Money (rating out of five)': 1, 'Seat Comfort (rating out of five)': 3, 'Cabin Staff Service (rating out of five)': 3, 'Food & Beverages (rating out of five)': 2, 'inflight_entertainment (rating out of five)': 'n/a', 'Wifi & Connectivity (rating out of five)': 'n/a', 'Ground Service (rating out of five)': 2, 'Recommended': 'no'}, {'Review Rating': '1', 'Review Writer': 'Mark Grimes', 'Title': '\"luggage was never loaded onto the flight\"', 'Date Published': '2021-10-04', 'Verify Status': 'Trip Verified', 'Country': 'United States', 'Aircraft': 'Boeing 777-200', 'Route': 'Atlanta to Kuwait via Amsterdam', 'Type Of Traveller': 'Business', 'Seat type': 'Economy Class', 'Date Flown': 'October 2021', 'Value For Money (rating out of five)': 1, 'Seat Comfort (rating out of five)': 1, 'Cabin Staff Service (rating out of five)': 1, 'Food & Beverages (rating out of five)': 'n/a', 'inflight_entertainment (rating out of five)': 'n/a', 'Wifi & Connectivity (rating out of five)': 'n/a', 'Ground Service (rating out of five)': 1, 'Recommended': 'no'}, {'Review Rating': '1', 'Review Writer': 'P Varmova', 'Title': '\"What happened with their customer service?\"', 'Date Published': '2021-10-02', 'Verify Status': 'Trip Verified', 'Country': 'United Kingdom', 'Aircraft': 'n/a', 'Route': 'London to Saint-Petersburg', 'Type Of Traveller': 'Solo Leisure', 'Seat type': 'Economy Class', 'Date Flown': 'June 2021', 'Value For Money (rating out of five)': 1, 'Seat Comfort (rating out of five)': 3, 'Cabin Staff Service (rating out of five)': 1, 'Food & Beverages (rating out of five)': 'n/a', 'inflight_entertainment (rating out of five)': 'n/a', 'Wifi & Connectivity (rating out of five)': 'n/a', 'Ground Service (rating out of five)': 1, 'Recommended': 'no'}, {'Review Rating': '5', 'Review Writer': 'N Birley', 'Title': '\"staff at the airport were terrible\"', 'Date Published': '2021-09-30', 'Verify Status': 'Trip Verified', 'Country': 'Ireland', 'Aircraft': 'n/a', 'Route': 'Belgrade to Dublin via Amsterdam', 'Type Of Traveller': 'Business', 'Seat type': 'Economy Class', 'Date Flown': 'September 2021', 'Value For Money (rating out of five)': 3, 'Seat Comfort (rating out of five)': 2, 'Cabin Staff Service (rating out of five)': 5, 'Food & Beverages (rating out of five)': 4, 'inflight_entertainment (rating out of five)': 'n/a', 'Wifi & Connectivity (rating out of five)': 1, 'Ground Service (rating out of five)': 1, 'Recommended': 'yes'}, {'Review Rating': '10', 'Review Writer': 'N Prokuski', 'Title': '\"Delightful experience!\"', 'Date Published': '2021-09-27', 'Verify Status': 'Not Verified', 'Country': 'United States', 'Aircraft': 'n/a', 'Route': 'Chicago to Amsterdam', 'Type Of Traveller': 'Couple Leisure', 'Seat type': 'First Class', 'Date Flown': 'September 2021', 'Value For Money (rating out of five)': 5, 'Seat Comfort (rating out of five)': 5, 'Cabin Staff Service (rating out of five)': 5, 'Food & Beverages (rating out of five)': 5, 'inflight_entertainment (rating out of five)': 4, 'Wifi & Connectivity (rating out of five)': 4, 'Ground Service (rating out of five)': 5, 'Recommended': 'yes'}, {'Review Rating': '3', 'Review Writer': 'S Derzeny ', 'Title': '\"took my small Samsonite hand luggage from me\"', 'Date Published': '2021-09-11', 'Verify Status': 'Trip Verified', 'Country': 'United Kingdom', 'Aircraft': 'B737-800 and a smaller one', 'Route': 'Budapest to Aberdeen via Amsterdam', 'Type Of Traveller': 'Solo Leisure', 'Seat type': 'Economy Class', 'Date Flown': 'September 2021', 'Value For Money (rating out of five)': 3, 'Seat Comfort (rating out of five)': 5, 'Cabin Staff Service (rating out of five)': 5, 'Food & Beverages (rating out of five)': 3, 'inflight_entertainment (rating out of five)': 'n/a', 'Wifi & Connectivity (rating out of five)': 'n/a', 'Ground Service (rating out of five)': 1, 'Recommended': 'no'}, {'Review Rating': '1', 'Review Writer': 'Fabiana Evans', 'Title': '\"worst flight of our lives\"', 'Date Published': '2021-09-10', 'Verify Status': 'Trip Verified', 'Country': 'United States', 'Aircraft': 'n/a', 'Route': 'Atlanta to Amsterd√£', 'Type Of Traveller': 'Couple Leisure', 'Seat type': 'Economy Class', 'Date Flown': 'September 2021', 'Value For Money (rating out of five)': 1, 'Seat Comfort (rating out of five)': 1, 'Cabin Staff Service (rating out of five)': 1, 'Food & Beverages (rating out of five)': 1, 'inflight_entertainment (rating out of five)': 1, 'Wifi & Connectivity (rating out of five)': 'n/a', 'Ground Service (rating out of five)': 1, 'Recommended': 'no'}]\n"
     ]
    }
   ],
   "source": [
    "# previewing the first page of reviews\n",
    "KLM_data = scrape(generate_page_urls(airline_urls[0], 123))\n",
    "print(KLM_data[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d6e5a",
   "metadata": {},
   "source": [
    "# 3. Saving the scraped data in a csv file\n",
    "Now that the data has been scraped we have made a function that converts the data into a csv file. First, we will explain the function and than we will briefly cover where the data will be saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a755695",
   "metadata": {},
   "source": [
    "## 3.1 The CSV function (with windows correction)\n",
    "For this function we use the writer() function of the csv package. The 'w' flag in the with statement indicates that the csv file will be overwritten each time. This is chosen as reviews are very rarely changed thus having historical data might be less relevant. Normally the csv.writer writes \\r\\n into the file directly. However, on windows it will write \\r\\r\\n because on Windows text mode each \\n will be translated into \\r\\n. Therefore we override the newlines with the parameter newline='' (empty string). Source: https://stackoverflow.com/questions/3348460/csv-file-written-with-python-has-blank-lines-between-each-row.\n",
    "\n",
    "As a delimiter we use the semi-colon (\";\") as this is not used in the scraped data which means that no suprise columns will be created. With writerow() the table headers are given. Lastly, we iterate over each review in the scrape data to make sure all data falls under the right header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43132036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a function that will convert the scraped data to a csv file\n",
    "def convert(airline_data, airline):\n",
    "    \"\"\"\n",
    "    A function that convert the scraped data of the airlinequality.com to a csv file\n",
    "  \n",
    "    Two parameter:\n",
    "        airline_data: A list of dictionaries created by the scrape() function of a specific airline\n",
    "        airline: the name of the airline\n",
    "        \n",
    "    Returns:\n",
    "        A csv file in the data folder and 'done!'. \n",
    "    \"\"\"\n",
    "    with open(\"../../data/\" + str(airline) + \"_data.csv\", \"w\", newline='', encoding='utf-8') as csv_file: \n",
    "        writer = csv.writer(csv_file, delimiter = \";\")\n",
    "        writer.writerow(['Review Rating',\n",
    "                         'Review Writer',\n",
    "                         'Title',\n",
    "                         'Date Published', \n",
    "                         'Verify Status',\n",
    "                         'Country',\n",
    "                         'Aircraft',\n",
    "                         'Route',\n",
    "                         'Type Of Traveller',\n",
    "                         'Seat type',\n",
    "                         'Date Flown',\n",
    "                         'Value For Money (rating out of five)',\n",
    "                         'Seat Comfort (rating out of five)',\n",
    "                         'Cabin Staff Service (rating out of five)',\n",
    "                         'Food & Beverages (rating out of five)',\n",
    "                         'inflight_entertainment (rating out of five)',\n",
    "                         'Wifi & Connectivity (rating out of five)',\n",
    "                         'Ground Service (rating out of five)',\n",
    "                         'Recommended'])\n",
    "    \n",
    "        for data in airline_data: \n",
    "            writer.writerow([data['Review Rating'],\n",
    "                             data['Review Writer'],\n",
    "                             data['Title'],\n",
    "                             data['Date Published'],\n",
    "                             data['Verify Status'],\n",
    "                             data['Country'],\n",
    "                             data['Aircraft'],\n",
    "                             data['Route'],\n",
    "                             data['Type Of Traveller'],\n",
    "                             data['Seat type'],\n",
    "                             data['Date Flown'],\n",
    "                             data['Value For Money (rating out of five)'],\n",
    "                             data['Seat Comfort (rating out of five)'],\n",
    "                             data['Cabin Staff Service (rating out of five)'],\n",
    "                             data['Food & Beverages (rating out of five)'],\n",
    "                             data['inflight_entertainment (rating out of five)'],\n",
    "                             data['Wifi & Connectivity (rating out of five)'],\n",
    "                             data['Ground Service (rating out of five)'],\n",
    "                             data['Recommended']])\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ec6b2",
   "metadata": {},
   "source": [
    "## 3.2 Saving the scraped data in a csv file\n",
    "Now we convert the KLM data to a csv file. As seen below, when the convert() function gets executed it prints 'done!' as output. This comfirms that the function was able to be executed without a problem. The csv file gets automatically stored in the data folder of this directory. This is because \"../../data/\" was added as a string to the file name. In addition, the airline name gets automatically added to the file name because the second parameter of the function is transformed to a string. We have manually added the date of when the data of KLM has been scraped to the csv file name. We gathered this date and time from the scrape function as this is printed when the function is executed (see paragraph 2.3).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9c43cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Making a csv file for the KLM data.\n",
    "convert(KLM_data, airlines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b7d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
